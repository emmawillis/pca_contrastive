Host: kn079
/project/6106383/ewillis/pca_contrastive/venv/bin/python
Python 3.11.4
Wed Nov 26 18:10:47 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:CA:00.0 Off |                    0 |
| N/A   40C    P0            112W /  350W |       0MiB /  46068MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
SCRIPT: train_triplet_full.py
ARGS: Namespace(seed=42, manifest='/project/aip-medilab/shared/picai/manifests/slices_manifest.csv', target='isup3', folds_train='1,2,3', folds_val='0', folds_test='4', batch_size=16, pos_ratio=0.33, use_skip=False, label6_column='merged_ISUP', sam_checkpoint='/project/aip-medilab/ewillis/pca_contrastive/mri_model_medsam_finetune/work_dir/MedSAM/medsam_vit_b.pth', proj_dim=512, histo_dir='/project/aip-medilab/shared/picai/histopathology_encodings/UNI2/projected_512D/embeddings_512', histo_marksheet_dir='/project/aip-medilab/shared/picai/histopathology_encodings/UNI2_splits', provider='all', triplet_epochs=40, triplet_patience=10, triplet_lr=1e-05, triplet_wd=0.0, triplet_margin=0.2, lr_max_iter=5, head_epochs=40, head_patience=10, head_lr=1e-05, head_wd=0.0, train_proj=False, outdir='/home/ewillis/projects/aip-medilab/ewillis/pca_contrastive/mri_model_medsam_finetune_2D/fixed_medsam_dims/triplet', wandb=True, wandb_project='mri-training', wandb_run_name='triplet-isup3')
!!!!!! classes_present [0, 1, 2]
wandb: Currently logged in as: jesande7 (jesande7-queens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.21.2
wandb: Run data is saved locally in /project/6106383/shared/picai/wandb/run-20251126_181116-2w9nhvh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run triplet-isup3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jesande7-queens/mri-training
wandb: üöÄ View run at https://wandb.ai/jesande7-queens/mri-training/runs/2w9nhvh2
[triplet] lr_proj=1e-05 | lr_enc=1e-06 | margin=0.2
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] new best (val BAL-acc=0.3333) snapshot stored in memory
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] new best (val BAL-acc=0.4839) snapshot stored in memory
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] new best (val BAL-acc=0.5019) snapshot stored in memory
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] new best (val BAL-acc=0.5160) snapshot stored in memory
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (2/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (3/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (4/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (5/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (6/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (7/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (8/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (9/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (10/10)
[triplet] Early stopping at epoch 15.
[HEAD 001] train: loss 0.8608 bacc 0.3711 acc 0.2479 f1 0.2303 || val: loss 0.1199 acc 0.0600 BAL-acc 0.3711 f1 0.1201 | acc[c0]=0.019  acc[c1]=0.685  acc[c2]=0.409 | auc[c0]=0.919  auc[c1]=0.477  auc[c2]=0.888 | macroAUC=0.761 | macroSens=0.371 macroSpec=0.670 | sens[c0]=0.019  sens[c1]=0.685  sens[c2]=0.409 | spec[c0]=1.000  spec[c1]=0.041  spec[c2]=0.969
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01     120    6026      94
   ISUP23       0     237     109
   ISUP45       0      65      45
  ‚Ü≥ [head] new best (val BAL-acc=0.3711) snapshot stored in memory
[HEAD 002] train: loss 0.7712 bacc 0.4956 acc 0.3958 f1 0.4066 || val: loss 0.1054 acc 0.4310 BAL-acc 0.5203 f1 0.3168 | acc[c0]=0.421  acc[c1]=0.558  acc[c2]=0.582 | auc[c0]=0.919  auc[c1]=0.634  auc[c2]=0.888 | macroAUC=0.814 | macroSens=0.520 macroSpec=0.795 | sens[c0]=0.421  sens[c1]=0.558  sens[c2]=0.582 | spec[c0]=0.982  spec[c1]=0.451  spec[c2]=0.952
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2629    3448     163
   ISUP23       2     193     151
   ISUP45       6      40      64
  ‚Ü≥ [head] new best (val BAL-acc=0.5203) snapshot stored in memory
[HEAD 003] train: loss 0.7485 bacc 0.5633 acc 0.5183 f1 0.4945 || val: loss 0.1032 acc 0.5081 BAL-acc 0.5360 f1 0.3597 | acc[c0]=0.497  acc[c1]=0.766  acc[c2]=0.345 | auc[c0]=0.919  auc[c1]=0.718  auc[c2]=0.889 | macroAUC=0.842 | macroSens=0.536 macroSpec=0.820 | sens[c0]=0.497  sens[c1]=0.766  sens[c2]=0.345 | spec[c0]=0.976  spec[c1]=0.503  spec[c2]=0.981
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3099    3090      51
   ISUP23       4     265      77
   ISUP45       7      65      38
  ‚Ü≥ [head] new best (val BAL-acc=0.5360) snapshot stored in memory
[HEAD 004] train: loss 0.7375 bacc 0.5790 acc 0.5473 f1 0.5142 || val: loss 0.1080 acc 0.4488 BAL-acc 0.5163 f1 0.3317 | acc[c0]=0.435  acc[c1]=0.714  acc[c2]=0.400 | auc[c0]=0.919  auc[c1]=0.650  auc[c2]=0.889 | macroAUC=0.819 | macroSens=0.516 macroSpec=0.800 | sens[c0]=0.435  sens[c1]=0.714  sens[c2]=0.400 | spec[c0]=0.980  spec[c1]=0.447  spec[c2]=0.974
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2714    3449      77
   ISUP23       3     247      96
   ISUP45       6      60      44
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 005] train: loss 0.7373 bacc 0.5871 acc 0.5508 f1 0.5190 || val: loss 0.1022 acc 0.5621 BAL-acc 0.5549 f1 0.3785 | acc[c0]=0.555  acc[c1]=0.746  acc[c2]=0.364 | auc[c0]=0.919  auc[c1]=0.736  auc[c2]=0.889 | macroAUC=0.848 | macroSens=0.555 macroSpec=0.838 | sens[c0]=0.555  sens[c1]=0.746  sens[c2]=0.364 | spec[c0]=0.971  spec[c1]=0.563  spec[c2]=0.978
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3466    2709      65
   ISUP23       6     258      82
   ISUP45       7      63      40
  ‚Ü≥ [head] new best (val BAL-acc=0.5549) snapshot stored in memory
[HEAD 006] train: loss 0.7271 bacc 0.5956 acc 0.5643 f1 0.5316 || val: loss 0.1039 acc 0.5418 BAL-acc 0.5478 f1 0.3576 | acc[c0]=0.541  acc[c1]=0.566  acc[c2]=0.536 | auc[c0]=0.919  auc[c1]=0.671  auc[c2]=0.889 | macroAUC=0.826 | macroSens=0.548 macroSpec=0.831 | sens[c0]=0.541  sens[c1]=0.566  sens[c2]=0.536 | spec[c0]=0.974  spec[c1]=0.566  spec[c2]=0.955
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3373    2715     152
   ISUP23       5     196     145
   ISUP45       7      44      59
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 007] train: loss 0.7252 bacc 0.6008 acc 0.5740 f1 0.5353 || val: loss 0.1041 acc 0.5417 BAL-acc 0.5554 f1 0.3671 | acc[c0]=0.537  acc[c1]=0.647  acc[c2]=0.482 | auc[c0]=0.919  auc[c1]=0.694  auc[c2]=0.889 | macroAUC=0.834 | macroSens=0.555 macroSpec=0.831 | sens[c0]=0.537  sens[c1]=0.647  sens[c2]=0.482 | spec[c0]=0.974  spec[c1]=0.554  spec[c2]=0.966
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3350    2780     110
   ISUP23       5     224     117
   ISUP45       7      50      53
  ‚Ü≥ [head] new best (val BAL-acc=0.5554) snapshot stored in memory
[HEAD 008] train: loss 0.7173 bacc 0.6152 acc 0.5832 f1 0.5475 || val: loss 0.1050 acc 0.5336 BAL-acc 0.5441 f1 0.3663 | acc[c0]=0.525  acc[c1]=0.734  acc[c2]=0.373 | auc[c0]=0.919  auc[c1]=0.713  auc[c2]=0.888 | macroAUC=0.840 | macroSens=0.544 macroSpec=0.828 | sens[c0]=0.525  sens[c1]=0.734  sens[c2]=0.373 | spec[c0]=0.974  spec[c1]=0.534  spec[c2]=0.976
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3278    2894      68
   ISUP23       5     254      87
   ISUP45       7      62      41
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 009] train: loss 0.7090 bacc 0.6220 acc 0.5869 f1 0.5543 || val: loss 0.1028 acc 0.5684 BAL-acc 0.5588 f1 0.3675 | acc[c0]=0.567  acc[c1]=0.618  acc[c2]=0.491 | auc[c0]=0.919  auc[c1]=0.703  auc[c2]=0.888 | macroAUC=0.837 | macroSens=0.559 macroSpec=0.840 | sens[c0]=0.567  sens[c1]=0.618  sens[c2]=0.491 | spec[c0]=0.971  spec[c1]=0.591  spec[c2]=0.958
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3538    2551     151
   ISUP23       5     214     127
   ISUP45       8      48      54
  ‚Ü≥ [head] new best (val BAL-acc=0.5588) snapshot stored in memory
[HEAD 010] train: loss 0.7176 bacc 0.6031 acc 0.5754 f1 0.5410 || val: loss 0.1052 acc 0.5411 BAL-acc 0.5539 f1 0.3470 | acc[c0]=0.539  acc[c1]=0.587  acc[c2]=0.536 | auc[c0]=0.919  auc[c1]=0.677  auc[c2]=0.886 | macroAUC=0.827 | macroSens=0.554 macroSpec=0.831 | sens[c0]=0.539  sens[c1]=0.587  sens[c2]=0.536 | spec[c0]=0.974  spec[c1]=0.577  spec[c2]=0.943
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3361    2640     239
   ISUP23       5     203     138
   ISUP45       7      44      59
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 011] train: loss 0.7162 bacc 0.6244 acc 0.5962 f1 0.5566 || val: loss 0.1040 acc 0.5466 BAL-acc 0.5511 f1 0.3598 | acc[c0]=0.541  acc[c1]=0.685  acc[c2]=0.427 | auc[c0]=0.919  auc[c1]=0.714  auc[c2]=0.886 | macroAUC=0.840 | macroSens=0.551 macroSpec=0.833 | sens[c0]=0.541  sens[c1]=0.685  sens[c2]=0.427 | spec[c0]=0.974  spec[c1]=0.561  spec[c2]=0.964
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3376    2729     135
   ISUP23       5     237     104
   ISUP45       7      56      47
  ‚Ü≥ [head] no improvement (2/10)
[HEAD 012] train: loss 0.7099 bacc 0.6237 acc 0.5972 f1 0.5571 || val: loss 0.1025 acc 0.5765 BAL-acc 0.5528 f1 0.3745 | acc[c0]=0.572  acc[c1]=0.723  acc[c2]=0.364 | auc[c0]=0.919  auc[c1]=0.746  auc[c2]=0.886 | macroAUC=0.850 | macroSens=0.553 macroSpec=0.841 | sens[c0]=0.572  sens[c1]=0.723  sens[c2]=0.364 | spec[c0]=0.965  spec[c1]=0.584  spec[c2]=0.973
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3570    2578      92
   ISUP23       8     250      88
   ISUP45       8      62      40
  ‚Ü≥ [head] no improvement (3/10)
[HEAD 013] train: loss 0.7146 bacc 0.6190 acc 0.5951 f1 0.5542 || val: loss 0.1019 acc 0.5869 BAL-acc 0.5599 f1 0.3808 | acc[c0]=0.582  acc[c1]=0.743  acc[c2]=0.355 | auc[c0]=0.919  auc[c1]=0.759  auc[c2]=0.885 | macroAUC=0.854 | macroSens=0.560 macroSpec=0.842 | sens[c0]=0.582  sens[c1]=0.743  sens[c2]=0.355 | spec[c0]=0.958  spec[c1]=0.594  spec[c2]=0.974
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3634    2517      89
   ISUP23      10     257      79
   ISUP45       9      62      39
  ‚Ü≥ [head] new best (val BAL-acc=0.5599) snapshot stored in memory
[HEAD 014] train: loss 0.7050 bacc 0.6234 acc 0.5934 f1 0.5549 || val: loss 0.1022 acc 0.5783 BAL-acc 0.5611 f1 0.3670 | acc[c0]=0.576  acc[c1]=0.662  acc[c2]=0.445 | auc[c0]=0.919  auc[c1]=0.725  auc[c2]=0.885 | macroAUC=0.843 | macroSens=0.561 macroSpec=0.839 | sens[c0]=0.576  sens[c1]=0.662  sens[c2]=0.445 | spec[c0]=0.958  spec[c1]=0.602  spec[c2]=0.958
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3594    2474     172
   ISUP23      10     229     107
   ISUP45       9      52      49
  ‚Ü≥ [head] new best (val BAL-acc=0.5611) snapshot stored in memory
[HEAD 015] train: loss 0.7100 bacc 0.6161 acc 0.5892 f1 0.5491 || val: loss 0.1060 acc 0.5254 BAL-acc 0.5363 f1 0.3485 | acc[c0]=0.517  acc[c1]=0.728  acc[c2]=0.364 | auc[c0]=0.919  auc[c1]=0.716  auc[c2]=0.883 | macroAUC=0.839 | macroSens=0.536 macroSpec=0.826 | sens[c0]=0.517  sens[c1]=0.728  sens[c2]=0.364 | spec[c0]=0.976  spec[c1]=0.534  spec[c2]=0.968
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3226    2895     119
   ISUP23       4     252      90
   ISUP45       7      63      40
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 016] train: loss 0.7029 bacc 0.6219 acc 0.5945 f1 0.5538 || val: loss 0.1042 acc 0.5521 BAL-acc 0.5556 f1 0.3507 | acc[c0]=0.548  acc[c1]=0.665  acc[c2]=0.455 | auc[c0]=0.919  auc[c1]=0.709  auc[c2]=0.881 | macroAUC=0.836 | macroSens=0.556 macroSpec=0.835 | sens[c0]=0.548  sens[c1]=0.665  sens[c2]=0.455 | spec[c0]=0.974  spec[c1]=0.582  spec[c2]=0.949
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3417    2601     222
   ISUP23       5     230     111
   ISUP45       7      53      50
  ‚Ü≥ [head] no improvement (2/10)
[HEAD 017] train: loss 0.7004 bacc 0.6277 acc 0.5990 f1 0.5560 || val: loss 0.1011 acc 0.6002 BAL-acc 0.5564 f1 0.3660 | acc[c0]=0.601  acc[c1]=0.650  acc[c2]=0.418 | auc[c0]=0.919  auc[c1]=0.747  auc[c2]=0.880 | macroAUC=0.849 | macroSens=0.556 macroSpec=0.845 | sens[c0]=0.601  sens[c1]=0.650  sens[c2]=0.418 | spec[c0]=0.952  spec[c1]=0.632  spec[c2]=0.952
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3748    2284     208
   ISUP23      12     225     109
   ISUP45      10      54      46
  ‚Ü≥ [head] no improvement (3/10)
[HEAD 018] train: loss 0.7052 bacc 0.6265 acc 0.6078 f1 0.5610 || val: loss 0.1033 acc 0.5702 BAL-acc 0.5585 f1 0.3517 | acc[c0]=0.568  acc[c1]=0.653  acc[c2]=0.455 | auc[c0]=0.919  auc[c1]=0.721  auc[c2]=0.879 | macroAUC=0.840 | macroSens=0.558 macroSpec=0.839 | sens[c0]=0.568  sens[c1]=0.653  sens[c2]=0.455 | spec[c0]=0.965  spec[c1]=0.610  spec[c2]=0.942
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3542    2426     272
   ISUP23       8     226     112
   ISUP45       8      52      50
  ‚Ü≥ [head] no improvement (4/10)
[HEAD 019] train: loss 0.6913 bacc 0.6324 acc 0.5984 f1 0.5629 || val: loss 0.1039 acc 0.5591 BAL-acc 0.5483 f1 0.3511 | acc[c0]=0.556  acc[c1]=0.662  acc[c2]=0.427 | auc[c0]=0.919  auc[c1]=0.717  auc[c2]=0.879 | macroAUC=0.838 | macroSens=0.548 macroSpec=0.835 | sens[c0]=0.556  sens[c1]=0.662  sens[c2]=0.427 | spec[c0]=0.967  spec[c1]=0.588  spec[c2]=0.951
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3468    2559     213
   ISUP23       8     229     109
   ISUP45       7      56      47
  ‚Ü≥ [head] no improvement (5/10)
[HEAD 020] train: loss 0.6981 bacc 0.6317 acc 0.5999 f1 0.5611 || val: loss 0.1095 acc 0.5157 BAL-acc 0.5335 f1 0.3448 | acc[c0]=0.502  acc[c1]=0.844  acc[c2]=0.255 | auc[c0]=0.918  auc[c1]=0.748  auc[c2]=0.877 | macroAUC=0.848 | macroSens=0.534 macroSpec=0.823 | sens[c0]=0.502  sens[c1]=0.844  sens[c2]=0.255 | spec[c0]=0.978  spec[c1]=0.511  spec[c2]=0.981
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3133    3030      77
   ISUP23       3     292      51
   ISUP45       7      75      28
  ‚Ü≥ [head] no improvement (6/10)
[HEAD 021] train: loss 0.7022 bacc 0.6185 acc 0.5867 f1 0.5507 || val: loss 0.1058 acc 0.5352 BAL-acc 0.5420 f1 0.3439 | acc[c0]=0.529  acc[c1]=0.688  acc[c2]=0.409 | auc[c0]=0.919  auc[c1]=0.707  auc[c2]=0.878 | macroAUC=0.835 | macroSens=0.542 macroSpec=0.830 | sens[c0]=0.529  sens[c1]=0.688  sens[c2]=0.409 | spec[c0]=0.976  spec[c1]=0.558  spec[c2]=0.955
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3301    2748     191
   ISUP23       4     238     104
   ISUP45       7      58      45
  ‚Ü≥ [head] no improvement (7/10)
[HEAD 022] train: loss 0.7043 bacc 0.6281 acc 0.6035 f1 0.5609 || val: loss 0.1044 acc 0.5591 BAL-acc 0.5515 f1 0.3431 | acc[c0]=0.556  acc[c1]=0.653  acc[c2]=0.445 | auc[c0]=0.919  auc[c1]=0.723  auc[c2]=0.873 | macroAUC=0.838 | macroSens=0.552 macroSpec=0.836 | sens[c0]=0.556  sens[c1]=0.653  sens[c2]=0.445 | spec[c0]=0.967  spec[c1]=0.603  spec[c2]=0.936
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3469    2464     307
   ISUP23       8     226     112
   ISUP45       7      54      49
  ‚Ü≥ [head] no improvement (8/10)
[HEAD 023] train: loss 0.6949 bacc 0.6317 acc 0.6054 f1 0.5603 || val: loss 0.1075 acc 0.5230 BAL-acc 0.5333 f1 0.3360 | acc[c0]=0.513  acc[c1]=0.769  acc[c2]=0.318 | auc[c0]=0.919  auc[c1]=0.730  auc[c2]=0.872 | macroAUC=0.840 | macroSens=0.533 macroSpec=0.825 | sens[c0]=0.513  sens[c1]=0.769  sens[c2]=0.318 | spec[c0]=0.976  spec[c1]=0.537  spec[c2]=0.963
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3201    2873     166
   ISUP23       4     266      76
   ISUP45       7      68      35
  ‚Ü≥ [head] no improvement (9/10)
[HEAD 024] train: loss 0.6924 bacc 0.6339 acc 0.6115 f1 0.5659 || val: loss 0.1036 acc 0.5753 BAL-acc 0.5556 f1 0.3547 | acc[c0]=0.572  acc[c1]=0.676  acc[c2]=0.418 | auc[c0]=0.919  auc[c1]=0.736  auc[c2]=0.874 | macroAUC=0.843 | macroSens=0.556 macroSpec=0.839 | sens[c0]=0.572  sens[c1]=0.676  sens[c2]=0.418 | spec[c0]=0.961  spec[c1]=0.609  spec[c2]=0.948
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3572    2429     239
   ISUP23       9     234     103
   ISUP45       9      55      46
  ‚Ü≥ [head] no improvement (10/10)
[head] Early stopping at epoch 24.
[FINAL VAL] loss 0.1022 acc 0.5783 f1 0.3670 | acc[c0]=0.576  acc[c1]=0.662  acc[c2]=0.445 | auc[c0]=0.919  auc[c1]=0.725  auc[c2]=0.885 | macroAUC=0.843 | macroSens=0.561 macroSpec=0.839 | sens[c0]=0.576  sens[c1]=0.662  sens[c2]=0.445 | spec[c0]=0.958  spec[c1]=0.602  spec[c2]=0.958
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3594    2474     172
   ISUP23      10     229     107
   ISUP45       9      52      49

=== Final model: Sensitivity at fixed specificity ===
       class |          AUC |  Sens@Spec40 |  Sens@Spec60 |  Sens@Spec80 |  Sens@Spec90 |  Sens@Spec95 |  Sens@Spec99
          c0 |        0.919 |        0.981 |        0.953 |        0.883 |        0.780 |        0.612 |        0.388
          c1 |        0.725 |        0.945 |        0.725 |        0.428 |        0.176 |        0.069 |        0.012
          c2 |        0.885 |        0.973 |        0.909 |        0.791 |        0.673 |        0.500 |        0.191
       macro |        0.843 |        0.966 |        0.862 |        0.701 |        0.543 |        0.394 |        0.197
[FINAL TEST] loss 0.1091 acc 0.5836 f1 0.3501 | acc[c0]=0.586  acc[c1]=0.615  acc[c2]=0.302 | auc[c0]=0.884  auc[c1]=0.688  auc[c2]=0.850 | macroAUC=0.807 | macroSens=0.501 macroSpec=0.824 | sens[c0]=0.586  sens[c1]=0.615  sens[c2]=0.302 | spec[c0]=0.908  spec[c1]=0.603  spec[c2]=0.963
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3663    2468     122
   ISUP23      33     254     126
   ISUP45      14      53      29

=== Final model: Sensitivity at fixed specificity ===
       class |          AUC |  Sens@Spec40 |  Sens@Spec60 |  Sens@Spec80 |  Sens@Spec90 |  Sens@Spec95 |  Sens@Spec99
          c0 |        0.884 |        0.984 |        0.953 |        0.825 |        0.618 |        0.385 |        0.123
          c1 |        0.688 |        0.867 |        0.688 |        0.375 |        0.172 |        0.097 |        0.007
          c2 |        0.850 |        0.917 |        0.875 |        0.833 |        0.688 |        0.375 |        0.146
       macro |        0.807 |        0.923 |        0.839 |        0.678 |        0.492 |        0.286 |        0.092
wandb: updating run metadata
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:         aux/head/lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      aux/lr_val/acc ‚ñà‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   aux/lr_val/acc_c0 ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   aux/lr_val/acc_c1 ‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   aux/lr_val/acc_c2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   aux/lr_val/auc_c0 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:   aux/lr_val/auc_c1 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ
wandb:   aux/lr_val/auc_c2 ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ
wandb:     aux/lr_val/bacc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/f1_macro ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                 +32 ...
wandb: 
wandb: Run summary:
wandb:         aux/head/lr 1e-05
wandb:      aux/lr_val/acc 0.93235
wandb:   aux/lr_val/acc_c0 0.99952
wandb:   aux/lr_val/acc_c1 0.01734
wandb:   aux/lr_val/acc_c2 0
wandb:   aux/lr_val/auc_c0 0.88741
wandb:   aux/lr_val/auc_c1 0.88128
wandb:   aux/lr_val/auc_c2 0.84105
wandb:     aux/lr_val/bacc 0.33895
wandb: aux/lr_val/f1_macro 0.33291
wandb:                 +32 ...
wandb: 
wandb: üöÄ View run triplet-isup3 at: https://wandb.ai/jesande7-queens/mri-training/runs/2w9nhvh2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jesande7-queens/mri-training
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251126_181116-2w9nhvh2/logs
