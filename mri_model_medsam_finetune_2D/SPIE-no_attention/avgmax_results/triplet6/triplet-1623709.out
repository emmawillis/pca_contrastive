Host: kn082
/project/6106383/ewillis/pca_contrastive/venv/bin/python
Python 3.11.4
Mon Dec 15 00:10:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:17:00.0 Off |                    0 |
| N/A   28C    P8             33W /  350W |       0MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
SCRIPT: train_triplet_full_no_attention_frozen_encoder.py
ARGS: Namespace(seed=42, manifest='/home/ewillis/projects/aip-medilab/shared/picai/manifests/slices_manifest.csv', target='isup6', folds_train='1,2,3', folds_val='0', folds_test='4', batch_size=16, pos_ratio=0.33, use_skip=False, label6_column='merged_ISUP', sam_checkpoint='/project/aip-medilab/ewillis/pca_contrastive/mri_model_medsam_finetune/work_dir/MedSAM/medsam_vit_b.pth', proj_dim=512, pool_mode='avgmax', gem_p_init=3.0, histo_dir='/project/aip-medilab/shared/picai/histopathology_encodings/UNI2/projected_512D/embeddings_512', histo_marksheet_dir='/project/aip-medilab/shared/picai/histopathology_encodings/UNI2_splits', provider='all', triplet_epochs=40, triplet_patience=10, triplet_lr=1e-05, triplet_wd=0.0, triplet_margin=0.2, lr_max_iter=5, head_epochs=40, head_patience=10, head_lr=1e-05, head_wd=0.0, train_proj=False, outdir='/home/ewillis/projects/aip-medilab/ewillis/pca_contrastive/mri_model_medsam_finetune_2D/SPIE-no_attention/avgmax_results/triplet6', wandb=True, wandb_project='mri-training', wandb_run_name='spie-noattn-triplet-isup6')
!!!!!! classes_present [0, 1, 2, 3, 4, 5]
wandb: Currently logged in as: jesande7 (jesande7-queens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.21.2
wandb: Run data is saved locally in /project/6106383/shared/picai/wandb/run-20251215_001056-jbyyxrk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spie-noattn-triplet-isup6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jesande7-queens/mri-training
wandb: üöÄ View run at https://wandb.ai/jesande7-queens/mri-training/runs/jbyyxrk7
[triplet] lr=1e-05 | wd=0 | margin=0.2 | encoder_frozen=YES
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] new best (val BAL-acc=0.1667) snapshot stored in memory
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (2/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (3/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (4/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (5/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (6/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (7/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (8/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (9/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 5 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=5).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
  ‚Ü≥ [triplet] no improvement (10/10)
[triplet] Early stopping at epoch 11.
[HEAD 001] train: loss 0.9802 bacc 0.1673 acc 0.1047 f1 0.0360 || val: loss 0.0309 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.484  auc[c1]=0.477  auc[c2]=0.487  auc[c3]=0.623  auc[c4]=0.547  auc[c5]=0.526 | macroAUC=0.524 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] new best (val BAL-acc=0.1667) snapshot stored in memory
[HEAD 002] train: loss 1.0447 bacc 0.1667 acc 0.1021 f1 0.0309 || val: loss 0.0365 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.459  auc[c1]=0.487  auc[c2]=0.584  auc[c3]=0.723  auc[c4]=0.649  auc[c5]=0.635 | macroAUC=0.590 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (1/10)
[HEAD 003] train: loss 1.0107 bacc 0.1667 acc 0.1062 f1 0.0320 || val: loss 0.0347 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.441  auc[c1]=0.496  auc[c2]=0.654  auc[c3]=0.782  auc[c4]=0.712  auc[c5]=0.701 | macroAUC=0.631 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (2/10)
[HEAD 004] train: loss 0.9933 bacc 0.1667 acc 0.1054 f1 0.0318 || val: loss 0.0295 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.431  auc[c1]=0.503  auc[c2]=0.691  auc[c3]=0.802  auc[c4]=0.750  auc[c5]=0.737 | macroAUC=0.652 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (3/10)
[HEAD 005] train: loss 1.0535 bacc 0.1667 acc 0.1013 f1 0.0306 || val: loss 0.0319 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.424  auc[c1]=0.506  auc[c2]=0.715  auc[c3]=0.818  auc[c4]=0.769  auc[c5]=0.760 | macroAUC=0.665 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (4/10)
[HEAD 006] train: loss 0.9153 bacc 0.1667 acc 0.1090 f1 0.0328 || val: loss 0.0290 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.421  auc[c1]=0.510  auc[c2]=0.729  auc[c3]=0.824  auc[c4]=0.779  auc[c5]=0.769 | macroAUC=0.672 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (5/10)
[HEAD 007] train: loss 1.0750 bacc 0.1667 acc 0.1035 f1 0.0313 || val: loss 0.0328 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.419  auc[c1]=0.513  auc[c2]=0.739  auc[c3]=0.829  auc[c4]=0.788  auc[c5]=0.779 | macroAUC=0.678 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (6/10)
[HEAD 008] train: loss 0.9679 bacc 0.1667 acc 0.1066 f1 0.0321 || val: loss 0.0255 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.418  auc[c1]=0.514  auc[c2]=0.744  auc[c3]=0.832  auc[c4]=0.791  auc[c5]=0.784 | macroAUC=0.680 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (7/10)
[HEAD 009] train: loss 0.9993 bacc 0.1667 acc 0.1055 f1 0.0318 || val: loss 0.0354 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.417  auc[c1]=0.516  auc[c2]=0.750  auc[c3]=0.835  auc[c4]=0.798  auc[c5]=0.788 | macroAUC=0.684 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (8/10)
[HEAD 010] train: loss 1.0455 bacc 0.1667 acc 0.1012 f1 0.0306 || val: loss 0.0314 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.417  auc[c1]=0.517  auc[c2]=0.752  auc[c3]=0.836  auc[c4]=0.800  auc[c5]=0.790 | macroAUC=0.685 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (9/10)
[HEAD 011] train: loss 0.8929 bacc 0.1667 acc 0.1070 f1 0.0322 || val: loss 0.0314 acc 0.1795 BAL-acc 0.1667 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.416  auc[c1]=0.518  auc[c2]=0.754  auc[c3]=0.837  auc[c4]=0.801  auc[c5]=0.791 | macroAUC=0.686 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0
  ‚Ü≥ [head] no improvement (10/10)
[head] Early stopping at epoch 11.
[FINAL VAL] loss 0.0309 acc 0.1795 f1 0.0507 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.484  auc[c1]=0.477  auc[c2]=0.487  auc[c3]=0.623  auc[c4]=0.547  auc[c5]=0.526 | macroAUC=0.524 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5038       0       0       0       0
    ISUP1       0    1202       0       0       0       0
    ISUP2       0     231       0       0       0       0
    ISUP3       0     115       0       0       0       0
    ISUP4       0      36       0       0       0       0
    ISUP5       0      74       0       0       0       0

=== Final model: Sensitivity at fixed specificity ===
       class |          AUC |  Sens@Spec40 |  Sens@Spec60 |  Sens@Spec80 |  Sens@Spec90 |  Sens@Spec95 |  Sens@Spec99
          c0 |        0.484 |        0.574 |        0.364 |        0.182 |        0.089 |        0.043 |        0.007
          c1 |        0.477 |        0.552 |        0.368 |        0.177 |        0.091 |        0.053 |        0.006
          c2 |        0.487 |        0.597 |        0.381 |        0.156 |        0.082 |        0.026 |        0.004
          c3 |        0.623 |        0.730 |        0.591 |        0.348 |        0.200 |        0.148 |        0.061
          c4 |        0.547 |        0.667 |        0.500 |        0.194 |        0.111 |        0.056 |        0.028
          c5 |        0.526 |        0.662 |        0.459 |        0.284 |        0.068 |        0.041 |        0.014
       macro |        0.524 |        0.630 |        0.444 |        0.224 |        0.107 |        0.061 |        0.020
[FINAL TEST] loss 0.0290 acc 0.1622 f1 0.0465 | acc[c0]=0.000  acc[c1]=1.000  acc[c2]=0.000  acc[c3]=0.000  acc[c4]=0.000  acc[c5]=0.000 | auc[c0]=0.499  auc[c1]=0.509  auc[c2]=0.527  auc[c3]=0.604  auc[c4]=0.591  auc[c5]=0.635 | macroAUC=0.561 | macroSens=0.167 macroSpec=0.833 | sens[c0]=0.000  sens[c1]=1.000  sens[c2]=0.000  sens[c3]=0.000  sens[c4]=0.000  sens[c5]=0.000 | spec[c0]=1.000  spec[c1]=0.000  spec[c2]=1.000  spec[c3]=1.000  spec[c4]=1.000  spec[c5]=1.000
Confusion matrix (LR val): rows=true, cols=pred
true\pred   ISUP0   ISUP1   ISUP2   ISUP3   ISUP4   ISUP5
    ISUP0       0    5156       0       0       0       0
    ISUP1       0    1097       0       0       0       0
    ISUP2       0     284       0       0       0       0
    ISUP3       0     129       0       0       0       0
    ISUP4       0      42       0       0       0       0
    ISUP5       0      54       0       0       0       0

=== Final model: Sensitivity at fixed specificity ===
       class |          AUC |  Sens@Spec40 |  Sens@Spec60 |  Sens@Spec80 |  Sens@Spec90 |  Sens@Spec95 |  Sens@Spec99
          c0 |        0.499 |        0.615 |        0.386 |        0.188 |        0.093 |        0.048 |        0.008
          c1 |        0.509 |        0.608 |        0.410 |        0.220 |        0.125 |        0.057 |        0.014
          c2 |        0.527 |        0.606 |        0.430 |        0.254 |        0.130 |        0.088 |        0.025
          c3 |        0.604 |        0.736 |        0.481 |        0.341 |        0.233 |        0.140 |        0.000
          c4 |        0.591 |        0.762 |        0.571 |        0.214 |        0.119 |        0.095 |        0.000
          c5 |        0.635 |        0.796 |        0.556 |        0.333 |        0.204 |        0.130 |        0.000
       macro |        0.561 |        0.687 |        0.472 |        0.258 |        0.151 |        0.093 |        0.008
wandb: updating run metadata
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       aux/head/lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    aux/lr_val/acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/acc_c5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: aux/lr_val/auc_c0 ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb: aux/lr_val/auc_c1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:               +49 ...
wandb: 
wandb: Run summary:
wandb:       aux/head/lr 1e-05
wandb:    aux/lr_val/acc 0.75239
wandb: aux/lr_val/acc_c0 1
wandb: aux/lr_val/acc_c1 0
wandb: aux/lr_val/acc_c2 0
wandb: aux/lr_val/acc_c3 0
wandb: aux/lr_val/acc_c4 0
wandb: aux/lr_val/acc_c5 0
wandb: aux/lr_val/auc_c0 0.54761
wandb: aux/lr_val/auc_c1 0.53734
wandb:               +49 ...
wandb: 
wandb: üöÄ View run spie-noattn-triplet-isup6 at: https://wandb.ai/jesande7-queens/mri-training/runs/jbyyxrk7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jesande7-queens/mri-training
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251215_001056-jbyyxrk7/logs
