Running TRIPLET job
/project/6106383/ewillis/pca_contrastive/venv/bin/python
Python 3.11.4
Fri Nov 28 00:27:19 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:65:00.0 Off |                    0 |
| N/A   36C    P0            110W /  350W |       0MiB /  46068MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
SCRIPT: train_triplet_oldSPIE.py
ARGS: Namespace(seed=42, manifest='/project/aip-medilab/shared/picai/manifests/slices_manifest.csv', target='isup3', folds_train='1,2,3', folds_val='0', folds_test='4', batch_size=16, pos_ratio=0.33, use_skip=False, label6_column='merged_ISUP', sam_checkpoint='/project/aip-medilab/ewillis/pca_contrastive/mri_model_medsam_finetune/work_dir/MedSAM/medsam_vit_b.pth', proj_dim=128, strip_neck=False, histo_dir='/home/ewillis/projects/aip-medilab/shared/picai/histopathology_encodings/UNI2/projected_128D/embeddings_128', histo_marksheet_dir='/home/ewillis/projects/aip-medilab/shared/picai/histopathology_encodings/UNI2_splits', provider='all', triplet_epochs=40, triplet_patience=10, triplet_lr=1e-05, triplet_wd=0.0, triplet_margin=0.2, lr_max_iter=15, head_epochs=40, head_patience=10, head_lr=1e-05, head_wd=0.0, train_proj=False, outdir='/home/ewillis/projects/aip-medilab/ewillis/pca_contrastive/new_SPIE/RESULTS_final/triplet_isup3', wandb=True, wandb_project='mri-training', wandb_run_name='newSPIE-triplet-isup6-128D')
wandb: Currently logged in as: jesande7 (jesande7-queens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.21.2
wandb: Run data is saved locally in /project/6106383/shared/picai/wandb/run-20251128_002739-8jimqirg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run newSPIE-triplet-isup6-128D
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jesande7-queens/mri-training
wandb: üöÄ View run at https://wandb.ai/jesande7-queens/mri-training/runs/8jimqirg

==============================
PHASE 1: Triplet Alignment
==============================

/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 001] train_loss=0.3581 val_loss=0.2075 LR_val_bacc=0.4986
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 002] train_loss=0.3016 val_loss=0.1731 LR_val_bacc=0.4909
  ‚Ü≥ no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 003] train_loss=0.2644 val_loss=0.1673 LR_val_bacc=0.5113
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 004] train_loss=0.2313 val_loss=0.1358 LR_val_bacc=0.5184
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 005] train_loss=0.2062 val_loss=0.1204 LR_val_bacc=0.5165
  ‚Ü≥ no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 006] train_loss=0.1876 val_loss=0.1115 LR_val_bacc=0.5276
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 007] train_loss=0.1685 val_loss=0.1167 LR_val_bacc=0.5168
  ‚Ü≥ no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 008] train_loss=0.1553 val_loss=0.1023 LR_val_bacc=0.5301
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 009] train_loss=0.1411 val_loss=0.0875 LR_val_bacc=0.5319
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 010] train_loss=0.1310 val_loss=0.0994 LR_val_bacc=0.5230
  ‚Ü≥ no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 011] train_loss=0.1207 val_loss=0.0823 LR_val_bacc=0.5114
  ‚Ü≥ no improvement (2/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 012] train_loss=0.1173 val_loss=0.0859 LR_val_bacc=0.5467
  ‚Ü≥ new best triplet model
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 013] train_loss=0.1113 val_loss=0.0993 LR_val_bacc=0.5077
  ‚Ü≥ no improvement (1/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 014] train_loss=0.1071 val_loss=0.0768 LR_val_bacc=0.5285
  ‚Ü≥ no improvement (2/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 015] train_loss=0.0963 val_loss=0.0724 LR_val_bacc=0.5042
  ‚Ü≥ no improvement (3/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 016] train_loss=0.0931 val_loss=0.0674 LR_val_bacc=0.5300
  ‚Ü≥ no improvement (4/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 017] train_loss=0.0890 val_loss=0.0678 LR_val_bacc=0.5207
  ‚Ü≥ no improvement (5/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 018] train_loss=0.0833 val_loss=0.0650 LR_val_bacc=0.5262
  ‚Ü≥ no improvement (6/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 019] train_loss=0.0789 val_loss=0.0712 LR_val_bacc=0.5349
  ‚Ü≥ no improvement (7/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 020] train_loss=0.0765 val_loss=0.0814 LR_val_bacc=0.5250
  ‚Ü≥ no improvement (8/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 021] train_loss=0.0710 val_loss=0.0663 LR_val_bacc=0.5123
  ‚Ü≥ no improvement (9/10)
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/project/6106383/ewillis/pca_contrastive/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 15 iteration(s) (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT

Increase the number of iterations to improve the convergence (max_iter=15).
You might also want to scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[TRIP 022] train_loss=0.0684 val_loss=0.0657 LR_val_bacc=0.5211
  ‚Ü≥ no improvement (10/10)
Triplet early stopping.

==============================
PHASE 2: Head (classification) training
==============================

[HEAD 001] train_loss=0.8918 train_bacc=0.3409 || val_loss=0.1357 val_bacc=0.3541 acc[c0]=0.000  acc[c1]=0.962  acc[c2]=0.100 | auc[c0]=0.878  auc[c1]=0.775  auc[c2]=0.828 | macroAUC=0.827 | macroSens=0.354 macroSpec=0.667 | sens[c0]=0.000  sens[c1]=0.962  sens[c2]=0.100 | spec[c0]=1.000  spec[c1]=0.021  spec[c2]=0.980
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01       0    6120     120
   ISUP23       0     333      13
   ISUP45       0      99      11
  ‚Ü≥ new best head model
[HEAD 002] train_loss=0.8189 train_bacc=0.5022 || val_loss=0.1362 val_bacc=0.4071 acc[c0]=0.000  acc[c1]=0.558  acc[c2]=0.664 | auc[c0]=0.878  auc[c1]=0.576  auc[c2]=0.833 | macroAUC=0.762 | macroSens=0.407 macroSpec=0.666 | sens[c0]=0.000  sens[c1]=0.558  sens[c2]=0.664 | spec[c0]=1.000  spec[c1]=0.257  spec[c2]=0.740
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01       0    4683    1557
   ISUP23       0     193     153
   ISUP45       0      37      73
  ‚Ü≥ new best head model
[HEAD 003] train_loss=0.7604 train_bacc=0.5217 || val_loss=0.1284 val_bacc=0.3848 acc[c0]=0.000  acc[c1]=0.691  acc[c2]=0.464 | auc[c0]=0.879  auc[c1]=0.581  auc[c2]=0.815 | macroAUC=0.758 | macroSens=0.385 macroSpec=0.666 | sens[c0]=0.000  sens[c1]=0.691  sens[c2]=0.464 | spec[c0]=1.000  spec[c1]=0.157  spec[c2]=0.840
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01       0    5296     944
   ISUP23       0     239     107
   ISUP45       0      59      51
  ‚Ü≥ no improvement (1/10)
[HEAD 004] train_loss=0.7034 train_bacc=0.5201 || val_loss=0.1269 val_bacc=0.4033 acc[c0]=0.006  acc[c1]=0.604  acc[c2]=0.600 | auc[c0]=0.877  auc[c1]=0.568  auc[c2]=0.798 | macroAUC=0.748 | macroSens=0.403 macroSpec=0.668 | sens[c0]=0.006  sens[c1]=0.604  sens[c2]=0.600 | spec[c0]=1.000  spec[c1]=0.257  spec[c2]=0.747
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01      37    4671    1532
   ISUP23       0     209     137
   ISUP45       0      44      66
  ‚Ü≥ no improvement (2/10)
[HEAD 005] train_loss=0.6596 train_bacc=0.5267 || val_loss=0.1208 val_bacc=0.4241 acc[c0]=0.079  acc[c1]=0.630  acc[c2]=0.564 | auc[c0]=0.878  auc[c1]=0.609  auc[c2]=0.786 | macroAUC=0.758 | macroSens=0.424 macroSpec=0.691 | sens[c0]=0.079  sens[c1]=0.630  sens[c2]=0.564 | spec[c0]=0.998  spec[c1]=0.319  spec[c2]=0.757
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01     491    4277    1472
   ISUP23       1     218     127
   ISUP45       0      48      62
  ‚Ü≥ new best head model
[HEAD 006] train_loss=0.6311 train_bacc=0.5663 || val_loss=0.1182 val_bacc=0.4687 acc[c0]=0.187  acc[c1]=0.601  acc[c2]=0.618 | auc[c0]=0.878  auc[c1]=0.626  auc[c2]=0.782 | macroAUC=0.762 | macroSens=0.469 macroSpec=0.726 | sens[c0]=0.187  sens[c1]=0.601  sens[c2]=0.618 | spec[c0]=0.996  spec[c1]=0.449  spec[c2]=0.734
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    1165    3461    1614
   ISUP23       1     208     137
   ISUP45       1      41      68
  ‚Ü≥ new best head model
[HEAD 007] train_loss=0.5973 train_bacc=0.5978 || val_loss=0.1168 val_bacc=0.4946 acc[c0]=0.267  acc[c1]=0.590  acc[c2]=0.627 | auc[c0]=0.877  auc[c1]=0.643  auc[c2]=0.773 | macroAUC=0.765 | macroSens=0.495 macroSpec=0.752 | sens[c0]=0.267  sens[c1]=0.590  sens[c2]=0.627 | spec[c0]=0.993  spec[c1]=0.528  spec[c2]=0.733
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    1666    2958    1616
   ISUP23       2     204     140
   ISUP45       1      40      69
  ‚Ü≥ new best head model
[HEAD 008] train_loss=0.5864 train_bacc=0.6227 || val_loss=0.1160 val_bacc=0.5091 acc[c0]=0.329  acc[c1]=0.662  acc[c2]=0.536 | auc[c0]=0.877  auc[c1]=0.666  auc[c2]=0.763 | macroAUC=0.769 | macroSens=0.509 macroSpec=0.769 | sens[c0]=0.329  sens[c1]=0.662  sens[c2]=0.536 | spec[c0]=0.985  spec[c1]=0.545  spec[c2]=0.778
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2053    2840    1347
   ISUP23       3     229     114
   ISUP45       4      47      59
  ‚Ü≥ new best head model
[HEAD 009] train_loss=0.5883 train_bacc=0.6330 || val_loss=0.1183 val_bacc=0.5164 acc[c0]=0.330  acc[c1]=0.610  acc[c2]=0.609 | auc[c0]=0.877  auc[c1]=0.661  auc[c2]=0.760 | macroAUC=0.766 | macroSens=0.516 macroSpec=0.770 | sens[c0]=0.330  sens[c1]=0.610  sens[c2]=0.609 | spec[c0]=0.987  spec[c1]=0.581  spec[c2]=0.744
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2061    2623    1556
   ISUP23       3     211     132
   ISUP45       3      40      67
  ‚Ü≥ new best head model
[HEAD 010] train_loss=0.5849 train_bacc=0.6477 || val_loss=0.1132 val_bacc=0.5330 acc[c0]=0.428  acc[c1]=0.598  acc[c2]=0.573 | auc[c0]=0.876  auc[c1]=0.693  auc[c2]=0.761 | macroAUC=0.777 | macroSens=0.533 macroSpec=0.795 | sens[c0]=0.428  sens[c1]=0.598  sens[c2]=0.573 | spec[c0]=0.965  spec[c1]=0.652  spec[c2]=0.768
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2670    2168    1402
   ISUP23      10     207     129
   ISUP45       6      41      63
  ‚Ü≥ new best head model
[HEAD 011] train_loss=0.5725 train_bacc=0.6589 || val_loss=0.1206 val_bacc=0.5178 acc[c0]=0.365  acc[c1]=0.679  acc[c2]=0.509 | auc[c0]=0.876  auc[c1]=0.684  auc[c2]=0.738 | macroAUC=0.766 | macroSens=0.518 macroSpec=0.779 | sens[c0]=0.365  sens[c1]=0.679  sens[c2]=0.509 | spec[c0]=0.976  spec[c1]=0.583  spec[c2]=0.777
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2278    2599    1363
   ISUP23       6     235     105
   ISUP45       5      49      56
  ‚Ü≥ no improvement (1/10)
[HEAD 012] train_loss=0.5803 train_bacc=0.6607 || val_loss=0.1179 val_bacc=0.5343 acc[c0]=0.411  acc[c1]=0.673  acc[c2]=0.518 | auc[c0]=0.876  auc[c1]=0.705  auc[c2]=0.735 | macroAUC=0.772 | macroSens=0.534 macroSpec=0.790 | sens[c0]=0.411  sens[c1]=0.673  sens[c2]=0.518 | spec[c0]=0.965  spec[c1]=0.623  spec[c2]=0.783
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2567    2346    1327
   ISUP23      10     233     103
   ISUP45       6      47      57
  ‚Ü≥ new best head model
[HEAD 013] train_loss=0.5585 train_bacc=0.6699 || val_loss=0.1158 val_bacc=0.5454 acc[c0]=0.467  acc[c1]=0.624  acc[c2]=0.545 | auc[c0]=0.876  auc[c1]=0.699  auc[c2]=0.753 | macroAUC=0.776 | macroSens=0.545 macroSpec=0.805 | sens[c0]=0.467  sens[c1]=0.624  sens[c2]=0.545 | spec[c0]=0.956  spec[c1]=0.667  spec[c2]=0.792
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2911    2074    1255
   ISUP23      12     216     118
   ISUP45       8      42      60
  ‚Ü≥ new best head model
[HEAD 014] train_loss=0.5867 train_bacc=0.6666 || val_loss=0.1201 val_bacc=0.5350 acc[c0]=0.441  acc[c1]=0.546  acc[c2]=0.618 | auc[c0]=0.876  auc[c1]=0.681  auc[c2]=0.758 | macroAUC=0.771 | macroSens=0.535 macroSpec=0.798 | sens[c0]=0.441  sens[c1]=0.546  sens[c2]=0.618 | spec[c0]=0.963  spec[c1]=0.688  spec[c2]=0.743
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2749    1947    1544
   ISUP23      10     189     147
   ISUP45       7      35      68
  ‚Ü≥ no improvement (1/10)
[HEAD 015] train_loss=0.5589 train_bacc=0.6759 || val_loss=0.1168 val_bacc=0.5418 acc[c0]=0.475  acc[c1]=0.642  acc[c2]=0.509 | auc[c0]=0.875  auc[c1]=0.708  auc[c2]=0.741 | macroAUC=0.775 | macroSens=0.542 macroSpec=0.808 | sens[c0]=0.475  sens[c1]=0.642  sens[c2]=0.509 | spec[c0]=0.956  spec[c1]=0.673  spec[c2]=0.794
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2962    2032    1246
   ISUP23      12     222     112
   ISUP45       8      46      56
  ‚Ü≥ no improvement (2/10)
[HEAD 016] train_loss=0.5763 train_bacc=0.6763 || val_loss=0.1160 val_bacc=0.5475 acc[c0]=0.494  acc[c1]=0.630  acc[c2]=0.518 | auc[c0]=0.876  auc[c1]=0.713  auc[c2]=0.745 | macroAUC=0.778 | macroSens=0.547 macroSpec=0.812 | sens[c0]=0.494  sens[c1]=0.630  sens[c2]=0.518 | spec[c0]=0.952  spec[c1]=0.691  spec[c2]=0.794
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3084    1914    1242
   ISUP23      14     218     114
   ISUP45       8      45      57
  ‚Ü≥ new best head model
[HEAD 017] train_loss=0.5754 train_bacc=0.6853 || val_loss=0.1165 val_bacc=0.5534 acc[c0]=0.510  acc[c1]=0.642  acc[c2]=0.509 | auc[c0]=0.875  auc[c1]=0.720  auc[c2]=0.740 | macroAUC=0.778 | macroSens=0.553 macroSpec=0.817 | sens[c0]=0.510  sens[c1]=0.642  sens[c2]=0.509 | spec[c0]=0.950  spec[c1]=0.696  spec[c2]=0.805
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3180    1883    1177
   ISUP23      15     222     109
   ISUP45       8      46      56
  ‚Ü≥ new best head model
[HEAD 018] train_loss=0.5880 train_bacc=0.6817 || val_loss=0.1174 val_bacc=0.5588 acc[c0]=0.504  acc[c1]=0.572  acc[c2]=0.600 | auc[c0]=0.875  auc[c1]=0.704  auc[c2]=0.750 | macroAUC=0.776 | macroSens=0.559 macroSpec=0.814 | sens[c0]=0.504  sens[c1]=0.572  sens[c2]=0.600 | spec[c0]=0.947  spec[c1]=0.717  spec[c2]=0.777
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3145    1762    1333
   ISUP23      15     198     133
   ISUP45       9      35      66
  ‚Ü≥ new best head model
[HEAD 019] train_loss=0.5698 train_bacc=0.6832 || val_loss=0.1166 val_bacc=0.5550 acc[c0]=0.534  acc[c1]=0.613  acc[c2]=0.518 | auc[c0]=0.874  auc[c1]=0.720  auc[c2]=0.738 | macroAUC=0.777 | macroSens=0.555 macroSpec=0.822 | sens[c0]=0.534  sens[c1]=0.613  sens[c2]=0.518 | spec[c0]=0.941  spec[c1]=0.721  spec[c2]=0.803
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    3332    1728    1180
   ISUP23      18     212     116
   ISUP45       9      44      57
  ‚Ü≥ no improvement (1/10)
[HEAD 020] train_loss=0.5685 train_bacc=0.6846 || val_loss=0.1216 val_bacc=0.5399 acc[c0]=0.463  acc[c1]=0.647  acc[c2]=0.509 | auc[c0]=0.875  auc[c1]=0.707  auc[c2]=0.729 | macroAUC=0.771 | macroSens=0.540 macroSpec=0.805 | sens[c0]=0.463  sens[c1]=0.647  sens[c2]=0.509 | spec[c0]=0.958  spec[c1]=0.657  spec[c2]=0.798
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2891    2129    1220
   ISUP23      11     224     111
   ISUP45       8      46      56
  ‚Ü≥ no improvement (2/10)
[HEAD 021] train_loss=0.5778 train_bacc=0.6860 || val_loss=0.1248 val_bacc=0.5369 acc[c0]=0.449  acc[c1]=0.598  acc[c2]=0.564 | auc[c0]=0.874  auc[c1]=0.696  auc[c2]=0.731 | macroAUC=0.767 | macroSens=0.537 macroSpec=0.799 | sens[c0]=0.449  sens[c1]=0.598  sens[c2]=0.564 | spec[c0]=0.956  spec[c1]=0.682  spec[c2]=0.759
Confusion matrix (LR val): rows=true, cols=pred
true\pred  ISUP01  ISUP23  ISUP45
   ISUP01    2801    1978    1461
   ISUP23      12     207     127
   ISUP45       8      40      62
  ‚Ü≥ no improvement (3/10)
